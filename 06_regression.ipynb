{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06: Regression\n",
    "\n",
    "If a linear relationship exists between two variables, then one variable can be predicted from the other by using the least squares regression equation. \n",
    "\n",
    "- **Least Squares Regression Equation**: The equation that minimizes the total of all squared prediction errors for known Y scores in the original correlation analysis. \n",
    "\n",
    "$$\n",
    "Y^\\prime = bX + a\n",
    "$$\n",
    "\n",
    "- $Y^\\prime$ is the predicted value. \n",
    "- $X$ represents the known value. \n",
    "- $b$ is the slope of the line \n",
    "- $a$ is the Y-intercept \n",
    "\n",
    "$$\n",
    "b = r\\sqrt{\\dfrac{SS_y}{SS_x}}\n",
    "$$\n",
    "\n",
    "- $SS_y$ is the sum of squares for all Y scores \n",
    "- $SS_x$ is the sum of squares for all x scores \n",
    "\n",
    "$$\n",
    "a = \\bar{Y} - b\\bar{X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss(X): \n",
    "    m = sum(X)/len(X)\n",
    "    return sum([(x - m)**2 for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spxy(X, Y): \n",
    "     mx = sum(X)/len(X)\n",
    "     my = sum(Y)/len(Y)\n",
    "     XY = []\n",
    "     for i in range(len(X)):\n",
    "          XY.append((X[i], Y[i]))\n",
    "     return sum((x-mx)*(y-my) for x,y in XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(X, Y): \n",
    "    return spxy(X, Y) / (math.sqrt(ss(X)*ss(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_b(r, ssy, ssx): \n",
    "    return r*math.sqrt(ssy/ssx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_a(mx, my, b): \n",
    "    return my - mx*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(x, b, a): \n",
    "    return (b*x) + a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 01\n",
    "\n",
    "Assume that an r of .30 describes the relationship between educational level (highest grade completed) and estimated number of hours spent reading each week. More specifically:\n",
    "\n",
    "X = Education Level \n",
    "\n",
    "Y = Weekly Reading Time \n",
    "\n",
    "$$\n",
    "\\bar{X} = 13, \\quad\n",
    "\\bar{Y} = 8, \\quad\n",
    "SS_x = 25, \\quad\n",
    "SS_y = 50, \\quad\n",
    "r = 0.30\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determine the least squares equation for predicting weekly reading time from educational level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4846, 0.4243)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = calc_b(r=0.3, ssy=50, ssx=25)\n",
    "a = calc_a(mx=13, my=8, b=b)\n",
    "\n",
    "round(a, 4), round(b, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Y^\\prime = 0.4243X + 2.4846\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Faith’s education level is 15. What is her predicted reading time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faith's predicted reading time is 8.849 hours.\n"
     ]
    }
   ],
   "source": [
    "Y = regression(x=15, a=a, b=b)\n",
    "\n",
    "print(f\"Faith's predicted reading time is {Y:.3f} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Keegan’s educational level is 11. What is his predicted reading time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keegan's predicted reading time is 7.151 hours.\n"
     ]
    }
   ],
   "source": [
    "Y = regression(x=11, a=a, b=b)\n",
    "\n",
    "print(f\"Keegan's predicted reading time is {Y:.3f} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Error \n",
    "\n",
    "- **Standard Error of Estimate ($S_{y|x}$)**: A rough measure of the average amount of predictive error. \n",
    "\n",
    "$$\n",
    "S_{y|x} = \\sqrt{\\dfrac{SS_{y|x}}{n - 2}} = \\sqrt{\\dfrac{\\sum(Y - Y^\\prime)^2}{n-2}} = \\sqrt{\\dfrac{SS_y(1-r)^2}{n-2}}\n",
    "$$ \n",
    "\n",
    "- It is a special kind of standard deviation that reflects the magnitude of predictive error. \n",
    "\n",
    "- Because any straight line, including the regression line, can be made to coincide with two data points, 2 degrees of freedom are lost, hence the denominator $n-2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_err(Y=[], r=0, ssy = False, n = False): \n",
    "    ssy = ssy if ssy else ss(Y)\n",
    "    n = n if n else len(Y)\n",
    "    return math.sqrt((ssy*(1-(r**2)))/(n-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions \n",
    "\n",
    "1. Linearity - use of regression equation requires that the underlying relationship be linear. \n",
    "\n",
    "2. Homoscedasticity - use of the standard error of estimate, $s_{x|y}$, assumes that except for chance, the dots in the original scatterplot will be dispersed equally about all segments of the regression line. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of $r^2$\n",
    "\n",
    "- **Squared Correlation Coefficient ($r^2$)**: The proportion of the total variability in one variable that is predictable from its relationship with  the other variable. \n",
    "\n",
    "- Primitive effort is to predict the $\\bar{Y}$ repeatedly for each value of $Y$. This provides a frame of reference against which to evaluate predictive effort based on correlation. \n",
    "\n",
    "- Errors should be smaller when customized predictions of $Y^\\prime$ from the least squares equations can be used compared to when only repetitive prediction of $\\bar{Y}$ is used. \n",
    "\n",
    "Gain in accuracy = $SS_y - SS_{y|x}$\n",
    "\n",
    "$$\n",
    "r^2 = \\dfrac{SS_{y^\\prime}}{SS_y} = \\dfrac{SS_y - SS_{y|x}}{SS_y}\n",
    "$$\n",
    "\n",
    "- $r^2$ is the proportion by which the variability of all $Y$ scores, as measured by $SS_y$ can be reduced. \n",
    "\n",
    "    - $r^2$ of 0.01 reflects weak relationship \n",
    "    - $r^2$ of 0.09 reflects moderate relationship \n",
    "    - $r^2$ of 0.25 reflects strong relationship \n",
    "\n",
    "- $r^2$ doesn't ensure cause-effect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Regression Equations \n",
    "\n",
    "- **Multiple Regression Equation**: A least squares equation that contains more than one predictor or X variable. \n",
    "\n",
    "**Example**\n",
    "$$\n",
    "Y^\\prime = .41(X_1) + .005(X_2) + 0.001(X_3) + 1.03\n",
    "$$\n",
    "\n",
    "Where $X_1, X_2, X_3$ are predictors of $Y^\\prime$(criterion variable)\n",
    "\n",
    "\n",
    "\n",
    "### Regression Toward the Mean\n",
    "- **Regression Toward the Mean**: A tendency for scores, particularly extreme scores, to shrink toward the mean. It occurs for individuals or subsets, but not entire groups. \n",
    "\n",
    "- **Regression Fallacy**: Occurs whenever regression toward the mean is interpreted as a real, rather than a change, effect. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949510482b8eeb0db0de64008f8e13a21a90dd06afd7a8e21dd837eed22f74f3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
